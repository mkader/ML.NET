## ML context
* ML context, which is the starting point for all the operations executed with ML.NET, such as loading data, creating and evaluating models, and getting detailed information about what is happening with the pipeline, such as errors or other events.
* ML context can also seed the environment for splitting data and helping others run your code to achieve similar results.
```csharp
using Microsoft.ML;
internal class Program
{
    private static void Main(string[] args)
    {
        var context = new MLContext();
        Console.WriteLine("Hello, World!");
    }
}
```
## Types of operations
* ML context provides various operations that the ML.NET API can perform, which can be divided into four categories.
* They are data operations, model operations, data transformations, and algorithms that can be used for training (trainers)
  1. The data operations category includes methods that allow ML.NET to load data from different sources.
  1. The model operations category includes methods that can be executed on the model itself, either on an existing model or a completely new one.
  1. The data transformations category includes methods used to process the data to get it into specific formats that machine learning algorithms might require.
  1. The trainers category is a set of algorithms built into ML.NET that can be used for different machine-learning scenarios.

## Data operations
* The data loading methods are available as part of the Data property of ML context (context)—these are:
  1. LoadFromBinary: Loads data from a binary file.
  1. LoadFromTextFile: Loads data from text files, including CSVs.
  1. LoadFromEnumerable: Loads data like arrays or lists.
  1. CreateDatabaseLoader: Connects to a SQL Server instance to retrieve data.
  1. Filter: As its name suggests, it is used for filtering data.
  1. TestTrainSplit: As its name suggests, it divides source data into a set for training a model and a set for testing and evaluating the trained model.
  1. Shuffle: As its name suggests, it is used to randomize the order in which data is processed during training, which is necessary to prevent training from stalling.

## Model operations
* Execute for the model itself to start making predictions and save a model once if it good. 
  1. Load: As its name suggests, it is used for loading an existing model.
  1. Save: As its name suggests, it is used for saving a model.
  1. CreatePredictionEngine: This method will let you make a prediction given a specific model input.

## Data transformations
* Some changes may have to be done to your data during processing—that’s where data transformations come into play. 
  1. Categorical: Applicable when working with data that can be categorized.
  1. Conversion: Applicable when converting from one data type to another.
  1. Text: When working with text columns, it is possible to transform those string values into their equivalent numerical values.
  1. ReplaceMissingValues: Replaces missing values within other data.
  1. DropColumns: Removes specific columns that might not be required.
  1. Concatenate: Concatenates multiple columns into one column.

## Trainers
* ML.NET comes with a set of built-in algorithms that are used for training your model based on input data for different scenarios—these algorithms are often referred to as trainers.
* ML.NET provides algorithms for scenarios such as clustering, regression, anomaly detection, ranking, multiclass or binary classification, etc.

## Adding a Model
* POCML Project ->  Right Click Add "Machine Learning Model" option -> select "Machine Learning Model (ML.NET)" and name it "POCModel.mbconfig" -> click Add.
* POCModel.mbconfig file is added, and a new Modeol Builder UI is displayed
* ![image](https://github.com/user-attachments/assets/c8b98412-641c-4bdb-93ae-3c0c9a4e4458)
* ![image](https://github.com/user-attachments/assets/6bb0859c-b258-4934-aab6-88d7edfe7910)

## Scenarios and tasks
* Before build the model and select the scenario.
* A scenario is how Model Builder describes the type of prediction that you want to make with your data, which correlates to a ML task. The task is the type of prediction based on the question being asked.
* Think of the scenario as a wrapper around a task; the task specifies the prediction type and uses various trainers (algorithms) to train the model.
* ![image](https://github.com/user-attachments/assets/4f450be7-5c77-407e-9820-c3e4c90f29f4)
* Use <a href="https://github.com/ed-freitas/ML.NET_Succinctly/blob/main/spam_assassin_tiny.csv">the dataset</a> to predict whether a text is a spam message (or not) using binary classification.
* The binary classification doesn’t appear as an option within the Model Builder UI, understand how the scenarios listed in the Model Builder UI relate to different ML tasks, such as binary classification. The binary classification task corresponds to the data classification scenario
* The Relationships between ML Tasks and Model Builder Scenarios
* ![image](https://github.com/user-attachments/assets/77aab080-da65-4de7-8a9b-9244e5932fe9)
* Binary classification is used to understand if something is positive or negative, if an email is a spam message or not, or in general, whether a particular item has a specific trait or property (or not).

## Training with Model Builder
* Choose "Data classification" the scenario -> "Select training environment" screen -> Select "Local (CPU)" 
  1. ![image](https://github.com/user-attachments/assets/be007fd0-5b0c-48d0-9275-0095ada0e0de)
* Click Next, Add data to the model -> Import "spam_assassin_tiny.csv" file -> Column to predict (Label) is set to target (the column text indicates whether the text is spam (1) or not (0)).
  1. ML.NET will use this column to predict the value based on what is read from the text column of the dataset
  1. ![image](https://github.com/user-attachments/assets/15fa0328-e84c-41fe-af8c-cc68baf5b9ee)
  1. Clicking Advanced data options.
      1. Model Builder has identified that the dataset contains two columns, text and target, as seen within Advanced data options, Column settings.
      2. The text column trains the model—it contains the actual email messages.
      3. In contrast, the target column contains the value (1 or 0) that is the value to predict.
      1. ![image](https://github.com/user-attachments/assets/7bfad88d-78d3-42ab-9a68-616661d48857)
* Click "Next Step" -> Click "Start Training", train the model with the dataset.
  1. ![image](https://github.com/user-attachments/assets/06d5def8-a3fe-479b-a3ea-d1ca8d179198)
  1. The time required to train the model is, in most cases, directly proportional to the size of the dataset.
  2. Larger dataset, the more computing resources and time are required.
  3. Typically, time is available; however, computing resources are mostly limited to the specs of the environment used.
  1. Instead of using <a href="https://www.kaggle.com/datasets/ganiyuolalekan/spam-assassin-email-classification-dataset">the complete dataset</a>, which includes 5,329 rows, <a href="https://github.com/ed-freitas/ML.NET_Succinctly/blob/main/spam_assassin_tiny.csv">I created a tiny subset with only the first 100 rows (99, given that the first row is a header)</a>.
  1. While the training takes place, the different trainers (algorithms) available for the ML task will be used—highlighted.
      1. ![image](https://github.com/user-attachments/assets/10336f02-1740-452e-9570-6e0e440ffe02)
  1. Advanced training options
      1. List of the trainers that are available and used. By default, all the trainers are selected.
      2. It is also possible to use fewer trainers, which can be done by unchecking one or more.
      3. ML.NET has good documentation that dives deeper into what these algorithms do and how to choose one by clicking on the When should I use each algorithm option.
At this stage, I wanted to show you that it is possible to change (enable or disable) some of the predefined algorithms for training a model in case the evaluation results are not optimal.
      1. ![image](https://github.com/user-attachments/assets/6b3f2d42-45c7-4083-8c53-b5e5ed041c45)
      
## Evaluating with Model Builder
Now that we have trained the model, we can evaluate it. To do that, let’s first click on the Evaluate option.

From the spam_assassin_tiny.csv file, copy one of the rows (without the target column value) and paste it into the text field above the Predict button. In my case, I copied row number six.

After clicking Predict, you’ll see how the model predicts based on the text input. The prediction is correct given that in this case the text input is not spam, but a legitimate message. Thus, the result is 0 (not spam) with a value of 67% certainty. The percentage is not a true mathematical probability, sometimes called a pseudo-probability.

Model Builder—Evaluate

Figure 2-r: Model Builder—Evaluate

Feel free to try with other text input from the complete dataset. Remember that the evaluation process is an opportunity to tweak and improve the model if the results are not as expected.

Because we have trained this model with a tiny dataset, not using the entire dataset, the percentages (confidence) of the results will not be as high (when correct) or low (when incorrect) as they would be if the model had been trained using the complete dataset. So, evaluate as many times as needed and feel free to retrain the model with a slightly larger dataset to improve the accuracy of the results.

The main reason I chose to explain all these Model Builder steps with a small dataset, not the large one, was to save you time while following along, as larger datasets require significantly more training time and resources from the system.

In your spare time, try training the model with the large dataset. Just make sure you have enough coffee available.

Consuming the model
With the model evaluation complete, the next step is to consume (use) the model created by Model Builder within our application.

As seen in the previous screenshot, Model Builder makes it very easy. There are two options: 1) either copy the Code snippet highlighted, or 2) use one of the available project templates, which can be added to your Visual Studio solution by clicking Add to solution.

Model Builder—Consume

Figure 2-s: Model Builder—Consume

In my case, I’ll go with option 1, which is to copy the code snippet and paste it into the Main method of Program.cs, as follows (code highlighted in bold).

Note: The line highlighted with a blue background is a new line I added (not part of the code snippet) to see the prediction result when running the program.

Note: The ellipsis markers (...) indicate extra text that I have explicitly removed to make the code more readable. The code snippet you’ll copy from Model Builder will have the full text. Please refer to the GitHub repo to get the complete code of Program.cs.

Note: The “using TestML;” statement is not part of the code snippet copied. It’s usually added (automatically) by Model Builder after the model is created, given that some additional C# files and a zip file are added to the project when the training finishes (we’ll explore these files later). If the “using TestML;” statement has not been added, please add it manually.

Code Listing 2-b: Program.cs–TestML (After copying the code snippet from Model Builder)

using Microsoft.ML;
using TestML;
internal class Program
{
    private static void Main(string[] args)
    {
        var context = new MLContext();
        Console.WriteLine("Hello, World!");
        //Load sample data.
        var sampleData = new TestModel.ModelInput()
        {
            Text = @"From gort44@excite.com...Mortgage Lenders & Brokers Are Ready to compete for your business. Whether a new home loan is what you seek or to refinance your current home loan at a lower interest rate, we can help!...This service is fast and free. Free information request form: PLEASE VISIT http://builtit4unow.com/pos...***",
        };
        //Load model and predict output.
        var result = TestModel.Predict(sampleData);
        Console.WriteLine($"Predicted: {result.PredictedLabel}");
    }
}
 Copy
Note: It is plausible that the snippet you copied from Model Builder might have a different Text value than mine, which means your prediction result might differ.

From the preceding code, some things stand out if you look closely at it. The first is that the content of the Text property of the sampleData object is spam to the naked eye. The second is that the sampleData object is passed as a parameter to the Predict method of the TestModel class.

As its name implies, the Predict method executes a prediction for the input data provided (sampleData) for the model created.

Finally, the result of the prediction is displayed by invoking result.PredictedLabel. To see this in action, let’s run the application. To do that, click on the run button in Visual Studio.

The Run Button Highlighted—Visual Studio

Figure 2-t: The Run Button Highlighted—Visual Studio

Once the application executes, you should see the following screen with the correct prediction value of 1 (indicating that the message is indeed spam).

The Execution of the Application—Microsoft Visual Studio Debugger

Figure 2-u: The Execution of the Application—Microsoft Visual Studio Debugger

Great! Model Builder has completely abstracted all the complexity of what ML.NET does behind the scenes to give us this prediction, providing us with a quick and easy implementation. The process is impressive, given that we’ve gone from nothing to having a spam-detection machine-learning model in just a few lines of code. Now, let’s have a look behind the scenes.

Generated model (TestModel.consumption.cs)
We’ve gone through the various steps provided by Model Builder, and behind the scenes a model was created. Let’s look at the code that was generated during that process.

Tip: Considering that the generated code we will explore might seem a bit complex, I suggest you review the high-level definitions of some of the concepts and objects we will encounter to get acquainted with the terminology.

Within Solution Explorer, click on the arrow icon next to the TestModel.mbconfig file to expand its content.

TestModel.mbconfig Expanded—Solution Explorer

Figure 2-v: TestModel.mbconfig Expanded—Solution Explorer

Notice the three files that Model Builder created. First, let’s open TestModel.consumption.cs and explore the code behind it.

Note: In most cases, when you open TestModel.consumption.cs, you might see one or two lines of comments generated by Model Builder when the file was created. For the listing below, I have explicitly removed those lines.

Code Listing 2-c: TestModel.consumption.cs

using Microsoft.ML;
using Microsoft.ML.Data;
namespace TestML
{
    public partial class TestModel
    {
        /// <summary>
        /// model input class for TestModel.
        /// </summary>
        #region model input class
        public class ModelInput
        {
            [LoadColumn(0)]
            [ColumnName(@"text")]
            public string Text { get; set; }
            [LoadColumn(1)]
            [ColumnName(@"target")]
            public string Target { get; set; }
        }
        #endregion
        /// <summary>
        /// model output class for TestModel.
        /// </summary>
        #region model output class
        public class ModelOutput
        {
            [ColumnName(@"text")]
            public float[] Text { get; set; }
            [ColumnName(@"target")]
            public uint Target { get; set; }
            [ColumnName(@"Features")]
            public float[] Features { get; set; }
            [ColumnName(@"PredictedLabel")]
            public string PredictedLabel { get; set; }
            [ColumnName(@"Score")]
            public float[] Score { get; set; }
        }
        #endregion
        private static string 
          MLNetModelPath = Path.GetFullPath("TestModel.zip");
        public static readonly 
           Lazy<PredictionEngine<ModelInput, ModelOutput>> 
           PredictEngine = new Lazy<PredictionEngine<ModelInput, 
             ModelOutput>>(() => CreatePredictEngine(), true);
        /// <summary>
        /// Use this method to predict <see cref="ModelInput"/>.
        /// </summary>
        /// <param name="input">model input.</param>
        /// <returns><seealso cref=" ModelOutput"/></returns>
        public static ModelOutput Predict(ModelInput input)
        {
            var predEngine = PredictEngine.Value;
            return predEngine.Predict(input);
        }
        private static PredictionEngine<ModelInput, ModelOutput> 
        CreatePredictEngine()
        {
            var mlContext = new MLContext();
            ITransformer mlModel = 
              mlContext.Model.Load(MLNetModelPath, out var _);
            return mlContext.Model.
              CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);
        }
    }
}
 Copy
Let’s review the code to understand it better. The ML.NET Model Builder automatically created this code.

First, we find the references to the two libraries that the code uses: Microsoft.ML and Microsoft.ML.Data.

The first (Microsoft.ML) includes ML.NET core methods, such as the trainers (algorithms), and the second (Microsoft.ML.Data) contains ML.NET methods that interact with the dataset used by the model.

Following that, within the TestML namespace, we find the TestModel class, declared as a partial class because it is partially declared (split) in both the TestModel.consumption.cs file and the TestModel.training.cs file.

Within the TestModel class, we find the ModelInput class, which defines as properties the two columns found within the dataset used: Text and Target.

Notice that both properties have decorators that map them to their respective columns within the dataset (ColumnName) and their position within that dataset (LoadColumn).

The ModelInput class, as its name implies, is used as the model’s input. On the other hand, the ModelOutput class is used as the model’s output.

Contrary to the ModelInput class, the properties of the ModelOutput class do not include the LoadColumn decorator, just ColumnName.

As part of the ModelOutput class, besides the Text and Target properties (which are also part of the ModelInput class), we find the Features, PredictedLabel, and Score properties.

Note: The Target property of the ModelOutput class is an unsigned integer (uint), contrary to the Target property of the ModelInput class, which is a string—this is because the Target property for a binary classification has to be an integer. Because the input dataset is in a CSV file, the value of Target as an input (even though it is a number) is a string. CSV files only store string values (including those that represent numbers).

These properties indicate the Features, the predicted value (PredictedLabel) column, and the confidence obtained for those results (Score).

Next, we find the declaration of the MLNetModelPath variable, which points to the model's metadata path (file name)—in our case TestModel.zip. This file includes the model’s schema, training information, and transformer chain metadata.

Following that, we find the PredictEngine variable declared, which is nothing else than the variable that will hold the reference to the prediction engine (PredictionEngine) to make predictions on the trained model.

The prediction engine (PredictEngine) will contain a value of the following type:

Lazy<PredictionEngine<ModelInput, ModelOutput>>

The creation of the prediction engine (PredictionEngine) is deferred until it is first used, accomplished by using Lazy initialization.

Notice that the ModelInput and ModelOutput classes are the type parameters of the prediction engine (PredictionEngine).

The prediction engine (PredictionEngine) is instantiated by creating a new object of type Lazy<PredictionEngine<ModelInput, ModelOutput>> as in:

public static readonly Lazy<PredictionEngine<ModelInput, ModelOutput>>

  PredictEngine = new Lazy<PredictionEngine<ModelInput,

  ModelOutput>>(() => CreatePredictEngine(), true);

The constructor receives as a first parameter a lambda function that creates the engine, () => CreatePredictEngine(), and the second parameter (true) indicates whether the instance can be used by multiple threads (thread-safe).

Next, we have the Predict method, which is used for making predictions based on the model, as follows.

public static ModelOutput Predict(ModelInput input)

{

  var predEngine = PredictEngine.Value;

  return predEngine.Predict(input);

}

The Predict method receives as a parameter a ModelInput instance (input), which, as its name implies, is the input data for the model.

The predicted value (PredictEngine.Value) is assigned to the predEngine variable. The result of invoking the predEngine.Predict method (which receives as a parameter the input data) is returned by the Predict method.

Then, we find the CreatePredictEngine method, which, as its name implies, creates the prediction engine instance.

private static PredictionEngine<ModelInput, ModelOutput> CreatePredictEngine()

{

  var mlContext = new MLContext();

  ITransformer mlModel = mlContext.Model.Load(MLNetModelPath, out var _);

  return mlContext.Model.

    CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);

}

The first thing the method does is create an instance of MLContext, which is assigned to the mlContext variable.

Then, the model is loaded—this is done by invoking the Load method from mlContext.Model, to which the model’s metadata path is passed as a parameter (MLNetModelPath). The out var _ parameter represents the modelInputSchema. The Load method returns the model loaded as an object (mlModel).

The prediction engine (PredictEngine) is finally created when the CreatePredictionEngine method from mlContext.Model is called, to which the object model (mlModel) is passed as a parameter.

So, overall, TestModel.consumption.cs contains the generated code responsible for creating the prediction engine and invoking it—thus, allowing the consumption of the model.

Generated model (TestModel.training.cs)
Next, let’s go back to Solution Explorer, open TestModel.training.cs, and explore the code behind it, which was also automatically generated by Model Builder.

Tip: Gentle reminder. Given that the generated code we will explore could seem a bit complex, I suggest you review the high-level definition of some of the concepts and objects we will encounter to get acquainted with the terminology.

Note: In most cases, when you open TestModel.training.cs, you might see one or two lines of comments generated by Model Builder when the file was created. For the listing below, I have explicitly removed those lines.

Code Listing 2-d: TestModel.training.cs

using Microsoft.ML.Trainers.FastTree;
using Microsoft.ML;
namespace TestML
{
    public partial class TestModel
    {
        /// <summary>
        /// Retrains model using the pipeline generated as part of the 
        /// training process. For more information on how to load data, 
        /// see aka.ms/loaddata.
        /// </summary>
        /// <param name="mlContext"></param>
        /// <param name="trainData"></param>
        /// <returns></returns>
        public static ITransformer RetrainPipeline(MLContext mlContext, 
            IDataView trainData)
        {
            var pipeline = BuildPipeline(mlContext);
            var model = pipeline.Fit(trainData);
            return model;
        }
        /// <summary>
        /// build the pipeline that is used from model builder. Use this 
        /// function to retrain model.
        /// </summary>
        /// <param name="mlContext"></param>
        /// <returns></returns>
        public static IEstimator<ITransformer> BuildPipeline(
            MLContext mlContext)
        {
            // Data process configuration with pipeline data 
            // transformations.
            var pipeline = mlContext.Transforms.Text.FeaturizeText
                  (inputColumnName:@"text",outputColumnName:@"text")      
              .Append(mlContext.Transforms.
                  Concatenate(@"Features", new []{@"text"})
              )      
              .Append(mlContext.Transforms.
                  Conversion.MapValueToKey(
                    outputColumnName:@"target",inputColumnName:@"target")
              )                                           
              .Append(mlContext.MulticlassClassification.
                  Trainers.OneVersusAll(binaryEstimator:mlContext.
                    BinaryClassification.Trainers.FastTree(new  
                      FastTreeBinaryTrainer.Options()
                      {
                        NumberOfLeaves=4,
                        MinimumExampleCountPerLeaf=20,
                        NumberOfTrees=4,
                        MaximumBinCountPerFeature=254,
                        FeatureFraction=1,
                        LearningRate=0.1,
                        LabelColumnName=@"target",
                        FeatureColumnName=@"Features"
                      }
                    ),
                    labelColumnName: @"target"
                  )
              )                                    
              .Append(mlContext.Transforms.Conversion.
                MapKeyToValue(
                  outputColumnName:@"PredictedLabel",
                  inputColumnName:@"PredictedLabel"
                )
              );
            return pipeline;
        }
    }
}
 Copy
The code begins with the using statements, where the ML.NET core (Microsoft.ML) and Microsoft.ML.Trainers.FastTree libraries are imported. The Microsoft.ML.Trainers.FastTree library contains the algorithm implementation used by the model.

Next, we find the TestModel class, also used within TestModel.consumption.cs, given that it is a partial class. The first method we come across is RetrainPipeline. As the comment indicates, this method is responsible for retraining the model once the pipeline has been built. Let’s inspect its code.

public static ITransformer RetrainPipeline(MLContext mlContext, IDataView   trainData)

{

  var pipeline = BuildPipeline(mlContext);

  var model = pipeline.Fit(trainData);

  return model;

}

So, as we can see, this method receives two parameters, an instance of MLContext and the training data (trainData) of type IDataView (used as the input and output of transforms).

The RetrainPipeline method returns an object that implements the ITransformer interface (responsible for transforming data within an ML.NET model pipeline).

The RetrainPipeline method works by building the model’s pipeline, in which the different transforms and algorithm(s) that will be used are specified.

With the objects in the pipeline created, the data (trainData) is passed to train the model by invoking the pipeline.Fit method. Finally, the model is returned.

So, the most complex part of the code is what happens within the BuildPipeline method. Let’s dissect it into smaller chunks to make sense of what is happening.

The BuildPipeline method receives as a parameter an MLContext instance and returns an object that implements the IEstimator<ITransformer> interface. The pipeline is built through a series of transformations that get subsequently added using mlContext.Transforms. The code begins with the call to:

Text.FeaturizeText(inputColumnName:@"text",outputColumnName:@"text")

The method transforms the input column strings (text) into numerical feature vectors (integers) that keep normalized counts of words and character n-grams.

Then, a series of Append methods are chained to FeaturizeText. For every Append method, a transform operation or trainer is passed as a parameter, creating the ML.NET pipeline. The first Append looks as follows:

.Append(mlContext.Transforms.Concatenate(@"Features", new []{@"text"})

What this does is invoke the Concatenate method from mlContext.Transforms to concatenate the various input columns into a new output column, in this case, Features.

The next Append looks as follows:

.Append(mlContext.Transforms.Conversion.MapValueToKey(

        outputColumnName:@"target",inputColumnName:@"target")

The MapValueToKey method from mlContext.Transforms.Conversion maps the input column (inputColumnName) to the output columns (outputColumnName) to convert categorical values into keys.

Moving on, the next Append looks as follows. Note this is where the magic happens.

.Append(mlContext.MulticlassClassification.

         Trainers.OneVersusAll(binaryEstimator:mlContext.

           BinaryClassification.Trainers.FastTree(new 

             FastTreeBinaryTrainer.Options()

             {

               NumberOfLeaves=4,

               MinimumExampleCountPerLeaf=20,

               NumberOfTrees=4,

               MaximumBinCountPerFeature=254,

               FeatureFraction=1,

               LearningRate=0.1,

               LabelColumnName=@"target",

               FeatureColumnName=@"Features"

             }

           ),

           labelColumnName: @"target"

         )

       )

The OneVersusAll method of mlContext.MulticlassClassification.Trainers receives a binary estimator (binaryEstimator) algorithm instance as a parameter. The one-versus-all technique is a general machine language algorithm that adapts a binary classification algorithm to handle a multiclass classification problem. See “Transformation to binary.”

The binary estimator instance represents the machine learning binary classification task employed by ML.NET that contains the trainers, utilities, and options used by the FastTree algorithms used for making predictions on the model.

Those options are then passed to the FastTree algorithms (highlighted in blue), predicting a target using a decision tree for binary classification.

Note: I’ve included a link to the official documentation for each option property, so you can look at what each one does and the allowed values for each.

The final part (labelColumnName: @"target") indicates that all predictions done by FastTree will be set on the column with the target label.

In short, TestModel.training.cs describes how the machine learning pipeline for the model works and behaves by specifying the various types of transformers and algorithms used and their sequence.

Summary
Throughout this chapter, we have employed Model Builder to generate a model for our data. Model Builder does a fantastic job of abstracting all the complexity behind writing the logic required to train, test, and consume a model.

As you have seen, the ML.NET classes are challenging to grasp, especially if you don’t have a machine learning background. If we didn’t have Model Builder to do the heavy lifting, we would have to experiment with many different values (for the option properties) and try different combinations or sequences to get the pipeline right. All in all, it would be a daunting and time-consuming activity that would make ML.NET no different from any other machine learning framework—thus, requiring a deeper understanding of machine learning.

By going over the code this way, I have tried to explain the underlying complexity of the Model Builder-generated code in relatively simple terms, so you can get a feeling of what happens behind the scenes, keeping a balance between simplicity and complexity.

For what remains of this book, I’ll go over other ML.NET scenarios and employ Model Builder to generate code for us. We’ll dive into the generated code for those new scenarios and compare how those look to the data classification scenario (binary classification) we just explored to understand differences and commonalities.
